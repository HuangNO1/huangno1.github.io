---
title: "Plug-and-Play Posterior Sampling for Blind Inverse Problems"
published: 2025-06-28T12:40:28+08:00
# 副標題
subtitle: ""
# 上次修改的時間
lastmod: 2025-06-28T12:40:28+08:00
draft: false
description: "中文標題-盲逆問題的即插即用後驗採樣：Blind-PnPDM 框架"
license: ""
tags: ["Blind-PnPDM", "CV", "Model", "DDPM", "DIFFUSION", "paper"]
category:  Paper
image: ./index/compressed/Figure1.png
lang: zh-TW
---


## 一、前言

中文標題--盲逆問題的即插即用後驗採樣：Blind-PnPDM 框架，[論文原文](https://arxiv.org/abs/2505.22923)，建議搭配論文原文食用，這篇論文很簡短，只有整整8頁，但是數學公式非常多，我自己瞄了幾眼，感到一種無力感( ´ﾟДﾟ`)

正好我上一篇讀的是 [DiffPir 論文](https://arxiv.org/abs/2305.08995)，是基於 PnP（Plug-and-Play） 作爲根基加上擴散模型。我這裡前面就簡單說逆問題，因爲前兩篇文章都提及了，這篇主要在於盲逆問題。

## 二、論文背景概述

### 2.1 逆問題

在科學領域中，逆問題本質上是從「結果」推斷「原因」的挑戰。這與「正向問題」形成對比，後者是從已知原因預測結果。

逆問題無處不在。在醫學影像領域，從 X 光、計算機斷層掃描（CT）或磁共振成像（MRI）等設備獲得的數據（結果），需要重建出人體內部的三維結構圖像（原因），以輔助疾病診斷 。

> Many problems in computational imaging, biomedical imaging, and computer vision can be formulated as inverse problems involving the recovery of high-quality images from low-quality observations. Imaging inverse problems are generally ill-posed, which means that multiple plausible clean images could lead to the same observation. It is thus common to introduce prior models on the desired images. While the literature on prior modeling of images is vast, current methods are often based on deep learning (DL), where a deep model is trained to map observations to images [1–3].

### 2.2 盲逆問題的特殊難點與應用場景

**盲逆問題是逆問題的一個特殊子類**，其獨特之處在於，不僅原始目標圖像未知，連導致圖像退化的「測量算子」（或稱「前向模型參數」）也是未知的 。這大大增加了問題的複雜性。傳統的逆問題解決方法通常假設測量算子是精確已知的，例如在去噪問題中，噪聲模型是預設的；在已知模糊核的去模糊問題中，模糊核是給定的。但在盲逆問題中，由於需要同時估計原始圖像和測量算子這兩個相互依賴的未知量，使得問題的難度呈指數級增長 。

盲逆問題在計算成像、生物醫學成像和電腦視覺等領域普遍存在，具有廣泛的應用。其中一個典型的例子是「盲圖像去模糊」（Blind Image Deblurring），即從一張模糊的照片中，同時恢復出清晰的原始圖像，並估計出造成模糊的「模糊核」（例如，相機在曝光期間的移動軌跡或失焦程度） 。另一個重要應用是「並行磁共振成像」（Parallel MRI），在這種技術中，需要同時重建圖像並估計線圈敏感度圖 。這些應用場景的共同特點是數據獲取過程中的不確定性，使得精確的系統校準變得困難或不可能。

**為何需要新的解決方案？**

儘管在影像逆問題領域取得了顯著進展，但現有的即插即用（Plug-and-Play, PnP）採樣方法主要集中於測量算子已知的情況。**對於盲逆問題，傳統的解決方案要麼依賴於明確定義的先驗模型，這往往難以捕捉真實世界圖像和測量算子的複雜特性**；要麼需要獨立的參數估計步驟，這可能導致次優解或增加計算複雜性，限制了它們的靈活性和適應性 。因此，業界迫切需要一個能夠同時、高效且有原則地解決圖像和測量算子聯合估計問題的新框架。

> While traditional PnP methods produce only point estimates, there is growing interest in PnP-based sampling methods that can produce solutions by sampling from the posterior distribution [29–31]. In particular, Plug-and-play Diffusion Models (PnPDM) [31] has proposed to leverage pre-trained diffusion models (DMs) as priors within PnP sampling formulation. Despite this progress, the existing work on PnP sampling has primarily focused on the problem of image recovery where the measurement operator is known exactly. There is little work on PnP sampling for blind inverse problems, where both the image and the measurement operator are unknown.

逆問題的「不適定性」是其核心挑戰，這意味著**許多不同的輸入組合都可能產生相同的觀測結果**。這種特性強烈要求引入「先驗知識」來約束可能的解空間。即插即用方法正是通過高效整合這些先驗知識來解決這類問題。如果即插即用方法能夠成功應用於盲逆問題，這將證明其在處理高度不確定性問題方面的強大能力。即插即用方法將複雜的「不適定」問題分解為數據一致性（與觀測數據匹配）和先驗約束（圖像或參數的合理性）兩個子問題，這種模塊化的分解策略是其成功的關鍵。

## 三、知識補充：PnP方法與擴散模型

### 3.1 影像處理中的「先驗知識」（prior models）：為何重要？

> 關於 Prior 就是目前我們正在做的黑洞反問題需要訓練出來的模型

如前所述，影像逆問題本質上是「不適定」的。這意味著從模糊、有噪聲或不完整的觀測數據中，可能有無數個「清晰圖像」和「測量算子」的組合能夠產生相同的觀測結果 。為了從這些無限的可能性中找到「合理」或「正確」的解決方案，我們必須引入「先驗知識」（prior models）。這些先驗知識是關於「我們期望的圖像應該具備什麼特性」或「測量算子應該有什麼樣的分佈」的假設或模型 。

在傳統的影像處理中，先驗知識通常以明確的數學形式表達，例如圖像應該是平滑的（如總變差，Total Variation, TV），或者在特定變換域（如小波變換）中是稀疏的 。然而，這些傳統先驗往往難以捕捉真實圖像的複雜高層次特徵。近年來，深度學習的發展為先驗建模帶來了革命性的突破。深度學習模型可以通過在大規模真實圖像數據上進行訓練，來隱式地捕獲這些複雜的先驗知識，而無需研究人員明確地寫出複雜的數學公式 。這種「學習型先驗」比傳統方法更加靈活和強大，能夠更好地反映真實數據的統計特性。

### 3.2 即插即用 (Plug-and-Play, PnP) 方法：概念、演變與優勢

即插即用（PnP）方法是一種廣泛應用的深度學習框架，專門用於解決影像逆問題。其核心理念是「規避了明確描述圖像完整概率密度函數的需要」，而是通過將現成的「圖像去噪器」作為隱式的圖像先驗來使用 。這種方法之所以被稱為「即插即用」，是因為它允許研究人員將任何現有的、最先進的圖像去噪器「插入」到優化或採樣算法中，而無需從頭重新設計整個逆問題的解決方案 。這是一個巨大的優勢，因為圖像去噪本身是一個高度活躍的研究領域，不斷有新的、性能更強大的去噪器被開發出來，這些進步可以直接被PnP框架所利用。

PnP算法通常在兩個核心步驟之間交替進行 ：

- **去噪步驟：** 在此步驟中，應用一個去噪器來「清潔」當前圖像估計，使其更符合「真實圖像」的先驗分佈。去噪器通過其學習到的知識，將圖像推向「清晰圖像流形」（manifold of clean images）。
- **數據一致性步驟：** 此步驟確保經過去噪的圖像估計仍然與原始觀測數據保持一致。這通常通過最小化數據保真項來實現。

PnP方法的發展經歷了從產生單一「點估計」（point estimates）到能夠從「後驗分佈」（posterior distribution）中生成多個可能解決方案的「PnP採樣方法」的演變 。後者提供了關於解決方案不確定性的更豐富信息。特別是近年來，PnP採樣方法與「擴散模型」的結合，如PnPDM（Plug-and-play Diffusion Models），進一步拓展了其能力 。

PnP方法的優勢顯而易見：它具有極高的靈活性，可以「即插即用」任何去噪器；結合最先進的深度去噪器，它在圖像超解析度、相位恢復、顯微鏡和醫學成像等多種逆問題中展現出卓越的性能 ；最重要的是，它避免了對先驗知識進行複雜的數學建模，只需訓練一個高效的去噪器。深度學習的進步，特別是強大的去噪器和生成模型的發展，為即插即用方法帶來了前所未有的「隱式先驗」能力。這些模型通過在大規模數據上學習，能夠隱式地掌握「什麼是真實圖像」的複雜分佈，從而使即插即用方法能夠處理更複雜、更真實的圖像恢復任務，不再受限於人為設計的簡單先驗。這是即插即用方法近年來取得巨大成功的關鍵因素，也是其從點估計到後驗採樣、從已知算子到盲逆問題演進的直接推動力。

### 3.3 擴散模型 (Diffusion Models, DMs)

> 雖然在上一篇關於 DiffPir 的文章中開頭處，我也有提及擴散模型，簡單來說就是**正向與逆向的過程機制**，我在這裡重提是避免下次想看這篇論文卻不知道這個知識點。我後面再出一篇文章寫關於擴散模型的先驗與後驗概念，整體框架是：**先驗+似然=後驗**

擴散模型是一種**新興的生成式 AI 算法**，它能夠從完全隨機的狀態（純粹的噪聲）中生成高度結構化的數據，例如逼真的圖像或連貫的文本 。其核心概念源於物理學中的擴散過程，即分子從高濃度區域向低濃度區域擴散的現象。

擴散模型的工作原理可以通過一個雙階段機制來理解：

1. **正向擴散過程 (Forward Diffusion Process)：** 在這個階段，模型會逐步、有控制地向原始清晰數據（如圖像）中添加高斯噪聲，直到原始數據完全被噪聲淹沒，變成一個純粹的隨機分佈。這個過程被設計為一個**馬爾可夫鏈**，意味著每一步的狀態僅依賴於前一步的狀態，確保了過程的簡潔性和可追溯性 。
2. **逆向擴散過程 (Reverse Diffusion Process)：** 這是擴散模型進行「學習」和「生成」的關鍵階段。模型訓練一個神經網絡來學習如何逆轉上述的噪聲添加過程，即如何從一個純粹的噪聲圖像中，一步一步地「去噪」，最終恢復出一個清晰、真實且具有細節的圖像 。通過學習在每個時間步預測並移除特定的噪聲模式，模型能夠從混亂中重建秩序。

擴散模型相較於其他生成模型（如生成對抗網絡GANs）具有顯著優勢 ：它們在生成高質量、細節豐富的圖像方面表現卓越；訓練過程更加穩定，較少出現GANs常見的「模式崩潰」（mode collapse）問題，從而生成更多樣化的輸出 ；同時，擴散模型還提供了對生成過程的高度控制，能夠生成條件化樣本，這對於特定應用場景至關重要 。

擴散模型與即插即用框架的結合，形成了 PnPDM。擴散模型的逆向過程本質上就是一個迭代的「去噪」過程，它從純粹的噪音中逐步恢復清晰圖像。而**即插即用方法的核心正是將「去噪器」作為其先驗**。這種內在的「去噪」機制使得擴散模型與即插即用框架天然契合，無需額外的複雜轉換。擴散模型不僅僅是一個生成模型，它更是一個極其強大的「學習型去噪器」，能夠在不同噪聲水平下進行去噪，這正是即插即用方法所需要的。這種內在的匹配性使得即插即用採樣能夠利用擴散模型強大的生成能力來探索後驗分佈，從而實現更為精確和穩定的逆問題解決方案 。

## 三、Blind-PnPDM 核心概念與創新

### 3.1 論文解決的核心問題：同時處理未知圖像與未知測量算子

核心目標是解決「盲逆問題」，這類問題的特殊挑戰在於，研究人員需要從受損的觀測數據 $y$ 中，同時恢復未知的目標圖像 $x$ 和未知的測量算子參數 $\theta$ 。在計算成像領域，這種觀測值 $y$ 通常可以模型化為 $y=A(\theta)x+e$，其中 $A(\theta)$ 代表由參數 $\theta$ 決定的測量算子，而 $e$ 則表示觀測過程中引入的噪聲 。例如，在盲圖像去模糊中，測量算子 $A(\theta)$ 就是由未知模糊核 $\theta$ 決定的卷積操作，而 $x$ 則是原始清晰圖像。

### 3.2 Blind-PnPDM 的創新之處：如何巧妙結合 PnP 與兩種擴散模型

Blind-PnPDM 提出了一個新穎的框架來解決盲逆問題，其核心創新在於通過「後驗採樣」來重構問題，並將其轉化為一個「交替式高斯去噪方案」 。這一方法的關鍵突破是**利用了兩個獨立但協同工作的預訓練擴散模型作為學習到的先驗知識**：

1. **圖像擴散模型 ($D_{\alpha}$):** 這個模型專門用於捕捉目標圖像 $x$ 的分佈特性，確保恢復的圖像在視覺上是真實且合理的。
2. **參數擴散模型 ($D_{\beta}$):** 這個模型則用於表徵測量算子參數 $\theta$ 的分佈，確保估計出的測量算子參數符合其應有的特性（例如，模糊核的特定形狀或稀疏性）。

這種將即插即用原則與雙擴散模型先驗相結合的設計，確保了方法的極大靈活性和易於適應性 。與傳統方法不同，Blind-PnPDM 不依賴於明確的數學先驗或獨立的參數估計步驟，而是將整個盲逆問題重新定義為一系列相互關聯的去噪子問題 。這種設計策略，為處理「雙重未知」的盲逆問題提供了一種精妙的解決方案。

盲逆問題的根本難點在於圖像和測量算子都是未知量。如果僅使用一個先驗模型（例如只針對圖像），那麼對測量算子的約束將會非常薄弱，導致問題難以收斂到一個合理的解。透過引入兩個獨立但協同工作的擴散模型先驗：一個專注於圖像的真實性，另一個專注於測量算子參數的合理性——這實現了「分而治之」的策略，使得複雜的聯合後驗分佈能夠被有效探索。這種設計方法也暗示了在處理多未知量逆問題時，為每個未知量提供專門且強大的先驗模型，是提升性能和穩定性的有效途徑。這也可能為未來在更複雜逆問題中應用多個領域特定的生成模型提供啟示。

### 3.3 與現有方法的區別和優勢

Blind-PnPDM 在解決盲逆問題方面填補了即插即用文獻中的一個重要空白。

- **與傳統 PnP 方法的區別：** 大多數現有的即插即用方法，包括早期的 PnPDM  和 Diffusion Plug-and-Play (DPnP) ，主要針對測量算子已知的情況 。Blind-PnPDM 則明確處理測量算子未知的情境。
- **與其他盲去模糊方法的區別：**
  - **Pan-DCP** 是一種基於優化的方法，雖然也能聯合估計圖像和模糊核，但它不屬於即插即用框架，且不利用深度學習的隱式先驗。
  - **DeblurGANv2** 是一種監督學習方法，能夠重建圖像，但它缺乏估計模糊核的能力。
  - **BlindDPS  和 GibbsDDRM** 雖然也利用擴散模型來解決盲逆問題，並在逆向擴散過程中聯合生成圖像和模糊核，但它們的處理方式與 Blind-PnPDM 的交替式吉布斯採樣框架有所不同。Blind-PnPDM 的方法更為通用，能將擴散模型作為圖像和測量算子兩者的即插即用先驗。

Blind-PnPDM 的優勢體現在多個方面：

- 它是**首個**將即插即用採樣方法應用於盲逆問題的框架，填補了該領域的空白。
- 它提供了一個**高效且有原則**的框架，適用於處理廣泛的盲成像逆問題。 
- 在盲圖像去模糊實驗中，無論是定量指標（如峰值信噪比 PSNR、結構相似性 SSIM）還是視覺保真度（如感知圖像補丁相似度 LPIPS），Blind-PnPDM 都**超越了現有的最先進方法**。
- 其**靈活性**在於能夠將擴散模型作為圖像和測量算子兩者的即插即用先驗，這是一個重要的突破。

傳統的即插即用方法多數產生單一的最佳估計（點估計）。然而，逆問題本質上是不適定的，可能存在多個「合理」的解。後驗採樣則能夠提供一個解的「分佈」，即多個可能的、符合觀測數據和先驗知識的解。這不僅提供了最佳解，還提供了關於解決方案「不確定性」的寶貴信息。這種從單一解到解分佈的轉變，反映了計算成像領域對「不確定性量化」日益增長的需求。在醫療診斷、安全監控等高風險應用中，了解解的可能範圍和置信度，往往比僅僅獲得一個單一的「最佳」解更為重要。擴散模型本身作為一種強大的生成模型，能夠從分佈中進行採樣，這使得將即插即用方法從點估計擴展到後驗採樣成為可能，從而提供了更豐富的解信息。

## 四、Blind-PnPDM 算法

### 4.1 整體框架：交替式吉布斯採樣 (Gibbs Sampling) 的直觀理解

Blind-PnPDM 的最終目標是從圖像 $x$ 和測量算子參數 $\theta$ 的聯合後驗分佈 $p(x, \theta|y)$ 中進行採樣。直接從這個高維且複雜的聯合分佈中採樣通常是極其困難的。為了解決這個挑戰，論文採用了吉布斯採樣（Gibbs Sampling）——馬爾可夫蒙特卡洛（MCMC）方法。

吉布斯採樣的核心思想是：如果直接從一個多變量聯合分佈中採樣很困難，那麼可以通過交替地從每個變量的「條件分佈」中採樣來實現。在 Blind-PnP DM 中，這意味著算法會交替地從以下兩個條件分佈中抽取樣本：

**1.  給定當前測量算子參數 $\theta^{(k)}$ 時，採樣圖像 $x$ 的條件分佈 $p(x|y, \theta^{(k)})$。**
**2.  給定新採樣的圖像 $x^{(k+1)}$ 時，採樣測量算子參數 $\theta$ 的條件分佈 $p(\theta|y, x^{(k+1)})$。**

為了更直觀地理解這個過程，可以想像在一個黑暗的房間裡，你試圖同時尋找一個物體（圖像 $x$）和一個控制物體位置的開關（參數 $\theta$）。你不知道它們的確切位置。但你知道它們之間存在某種關聯。吉布斯採樣的過程就像：你首先根據對開關位置的模糊猜測，去摸索物體的可能位置；然後，根據你摸到的物體位置，修正你對開關位置的猜測；如此反覆迭代。通過這種交替迭代，複雜的聯合問題被分解為兩個相對簡單的子問題，最終你就能夠同時找到物體和開關的合理估計。這種分解策略使得算法能夠在複雜的逆向問題中高效地探索解空間。

### 4.2 僞代碼解析（Algorithm 1）

> 這裡看不懂沒關係，因爲我也沒看懂(#`Д´)ﾉ，只需要知道他每一步在做什麼就好了

![algo1.png](https://imgpoi.com/i/FV2QSE.png)

1. **輸入 (Line 1):**

    算法需要以下初始設定和預訓練模型：

    * $x^{(0)}$: 圖像的初始估計，通常是一個隨機或簡單的圖像。
    * $\theta^{(0)}$: 測量算子參數的初始估計，例如模糊核的初始猜測。
    * $K$: 算法將執行的總迭代次數。
    * $\{\rho_{x^k}\}(k)$: 圖像採樣的耦合強度（或等效降噪水平）時間表。這是一個隨迭代次數 $k$ 變化的正參數序列。論文中提到採用退火策略，例如 $\max(0.9^k * 0.3, 0.1)$。這表示 $\rho_x$ 會隨著迭代次數的增加而逐漸衰減，從而逐步降低採樣過程中的隨機性，幫助算法向穩定解收斂。
    * $\{\rho_{\theta^k}\}(k)$: 測量算子參數採樣的耦合強度時間表，同樣隨 $k$ 變化。論文中給出的例子是 $\max(0.9^k * 0.1, 0.05)$。
    * $D_\alpha$: 預訓練的圖像擴散模型，作為圖像的先驗知識。
    * $D_\beta$: 預訓練的參數擴散模型，作為測量算子參數的先驗知識。

2. **迭代循環 (Lines 2-10)：** 算法的核心是一個循環，從 k=0 到 K−1 進行迭代。在每一次迭代中，算法會交替更新圖像和測量算子參數。

3.  **目標**: 在給定前測量算子參數 $\theta^{(k)}$ 的情況下，更新圖像 $x$ 的估計。

    * **分解策略**: 這一採樣步驟被分解為兩個子步驟：似然步驟 (LikelihoodStep) 和先驗步驟 (PriorStep)，這遵循了分岔吉布斯採樣器 (Split Gibbs Samplers, SGS) 框架。
    * **似然步驟 (LikelihoodStep) (Line 4)**: $z^{(k)} = \text{LikelihoodStep}(x^{(k)}, \theta^{(k)}, \rho_{x^k})$
        * **作用**: 此步驟引入一個輔助變量 $z^{(k)}$。它主要負責確保新的圖像估計與觀測數據 $y$ 保持一致（數據保真），同時也與上一輪的圖像估計 $x^{(k)}$ 保持一定的耦合。
        * **直觀理解**: 可以將 $z^{(k)}$ 想像成對 $x^{(k)}$ 的一個「噪音化觀測」，這個觀測既考慮了原始數據 $y$ (透過測量算子 $A(\theta^{(k)})$ 的作用)，也考慮了對 $x$ 的上一個猜測 $x^{(k)}$。
        * **數學公式 (8) 詳解**: $z^{(k)} \sim \exp(-1/2 \ ||y-A(\theta^{(k)})z||^2 - 1/(2\rho_{x^k}) \ ||z-x^{(k)}||^2)$
            * $||y-A(\theta^{(k)})z||^2$: 這是「數據保真項」，它衡量了如果圖像為 $z$ 且測量算子為 $A(\theta^{(k)})$ 時，將觀測到的測量 $A(\theta^{(k)})z$ 與實際觀測值 $y$ 之間的差異。這個項的目標是使差異最小，以確保 $z$ 與觀測數據一致。
            * $||z-x^{(k)}||^2$: 這是「耦合項」。它將輔助變量 $z$ 與上一輪的圖像估計 $x^{(k)}$ 聯繫起來。$\rho_{x^k}$ 是耦合強度參數，控制 $z$ 有多大程度上接近舊圖像 $x^{(k)}$。$\rho_{x^k}$ 越小，耦合越強，$z$ 越接近 $x^{(k)}$。
            * 整個表達式表明 $z^{(k)}$ 是從一個高斯分佈中採樣的，這個分佈的均值同時考慮了數據一致性與和 $x^{(k)}$ 的接近性。
    * **先驗步驟 ($PriorStep_x$) (Line 5)**: $x^{(k+1)} = PriorStep_x(z^{(k)}, ρ_x^{(k)}, D_\alpha)$
        * **作用**: 此步驟利用預訓練的圖像擴散模型 $D_\alpha$ 作為先驗，對 $z^{(k)}$ 進行「去噪」，從而生成新的圖像估計 $x^{(k+1)}$。
        * **直觀理解**: $z^{(k)}$ 是一個結合了數據和舊估計的「噪音」圖像。現在，我們運用強大的擴散模型去噪器 $D_\alpha$ 來「清潔」它，使其在視覺上更像一個真實的圖像。
        * **數學公式 (4b) 詳解**: $x^{(k+1)} \sim \exp(-g(x) - 1/(2\rho_{x^k}) \ ||x-z^{(k)}||^2)$
            * $g(x)$: 這是圖像的「先驗勢函數」，表示為 $-\log p(x)$。它隱式地由擴散模型 $D_\alpha$ 所代表。擴散模型通過學習大量真實圖像的數據分佈，從而捕獲了 $g(x)$ 所代表的先驗知識。
            * $||x-z^{(k)}||^2$: 這是「數據項」，它將 $x$ 拉向 $z^{(k)}$。在擴散模型的框架下，這一步通常用於降噪或 EDM (Elucidated Diffusion Model) 框架內運行 $D_\alpha$ 的推理過程來完成的，從一個特定的噪聲水平 $t^*$ (其中 $t^* \sim \mathcal{U}(0, T)$) 開始，去噪到 $t=0$。

4.  **測量算子參數更新步驟**: 從 $p(\theta|y, x^{(k+1)})$ 採樣 (Lines 6-9)

    * **目標**: 在給定觀測數據 $y$ 和更新的圖像 $x^{(k+1)}$ 的情況下，更新測量算子參數 $\theta$ 的估計。

    * **分解策略**: 類似於圖像更新，這一步也分解為似然步驟和先驗步驟。

    * **似然步驟 (LikelihoodStep_$\theta$) (Line 7)**: $v^{(k)} = LikelihoodStep_\theta(x^{(k+1)}, \theta^{(k)}, ρ_\theta^{(k)})$
        * **作用**: 引入一個輔助變量 $v^{(k)}$。它確保新的參數估計與觀測數據 $y$ 保持一致，同時也與上一輪的參數估計 $\theta^{(k)}$ 保持耦合。
        * **直觀理解**: $v^{(k)}$ 可以被視為對 $\theta^{(k)}$ 的一個「噪音化觀測」，這個觀測既考慮了原始數據 $y$，也考慮了對 $\theta^{(k)}$ 的上一個猜測 $\theta^{(k)}$。
        * **數學公式 (9) 詳解**: $v^{(k)} \sim \exp(-1/2 \ ||y-A(v)x^{(k+1)}||^2 - 1/(2\rho_{\theta^k}) \ ||v-\theta^{(k)}||^2)$
            * $||y-A(v)x^{(k+1)}||^2$: 這是「數據保真項」。它衡量了如果圖像為 $x^{(k+1)}$ 且測量算子為 $A(v)$ 時，預測的觀測值 $A(v)x^{(k+1)}$ 與實際觀測值 $y$ 之間的差異。目標是使這個差異最小，確保 $v$ 與觀測數據一致。
            * $||v-\theta^{(k)}||^2$: 這是「耦合項」。它將輔助變量 $v$ 與上一輪的參數估計 $\theta^{(k)}$ 聯繫起來。$\rho_{\theta^k}$ 是耦合強度參數。

    * **先驗步驟 (PriorStep_$\theta$) (Line 8)**: $\theta^{(k+1)} = \text{PriorStep}_\theta(v^{(k)}, \rho_{\theta^k}, D_{\beta})$
        * **作用**: 此步驟利用預訓練的參數擴散模型 $D_\beta$ 作為先驗，對 $v^{(k)}$ 進行「去噪」，從而生成新的參數估計 $\theta^{(k+1)}$。
        * **直觀理解**: $v^{(k)}$ 是一個結合了數據和舊估計的「噪音」參數。現在，我們運用強大的擴散模型去噪器 $D_\beta$ 來「清潔」它，使其在統計特性上更像一個真實的測量算子參數。
        * **數學公式 (7b) 詳解**: $\theta^{(k+1)} \sim \exp(-h(\theta) - 1/(2\rho_{\theta^k}) \ ||\theta-v^{(k)}||^2)$
            * $h(\theta)$: 這是測量算子參數的「先驗勢函數」，表示為 $-\log p(\theta)$。它隱式地由擴散模型 $D_\beta$ 所代表。
            * $||v-\theta^{(k)}||^2$: 這是一個「去噪」項，它將 $\theta$ 拉向 $v^{(k)}$。在擴散模型的框架下，這一步相當於用噪聲水平 $\rho_{\theta^k}$ 進行去噪。

5.  **退火策略 (Annealing Schedules)**:

    論文強調，為了加速馬爾可夫鏈的混合時間並避免收斂到不好的局部最小值，$\rho_x$ 和 $\rho_\theta$ 都採用了隨迭代次數 $k$ 變化的退火策略。這表示在算法初期允許更大的隨機性（更大的 $\rho$ 值），以便更好地探索解空間；而在後期則逐漸減小隨機性（減小 $\rho$ 值），幫助算法穩定地收斂到一個高質量解。

### 4.3 關鍵數學公式 (5), (8), (9) 深度解析

這些數學公式是 Blind-PnPDM 算法運作的基石，它們精確地定義了採樣過程中的概率分佈和目標函數。

**公式 (5): 聯合後驗分佈**

$p(x, \theta |y) \propto p(y|x, \theta)p(x)p(\theta) = \exp(-f(x, \theta; y) - g(x) - h(\theta))$

* **意義**：這個公式是整個 Blind-PnP DM 框架的基礎，它代表了在給定觀測數據 $y$ 的情況下，目標圖像 $x$ 和測量算子參數 $\theta$ 的聯合後驗概率分佈。算法的最終目標就是從這個分佈中採樣，以獲得對 $x$ 和 $\theta$ 的最佳估計。

* **組成部分**：

    * $p(y|x, \theta)$ 或 $f(x, \theta; y) := -\log p(y|x, \theta)$：這是**似然項 (Likelihood Term)** 或似然勢函數。它衡量了在給定圖像 $x$ 和參數 $\theta$ 的情況下，觀察到數據 $y$ 的可能性。這個值越小，表示 $x$ 和 $\theta$ 越能很好地解釋觀測數據 $y$。在線性系統 $y=A(\theta)x+e$ 中，如果噪聲 $e$ 是高斯分佈，則 $f(x, \theta; y)$ 通常是 $1/2 \ ||y-A(\theta)x||^2$，即最小二乘數據保真項。

    * $p(x)$ 或 $g(x) := -\log p(x)$：這是**圖像先驗項 (Image Prior Term)** 或圖像先驗勢函數。它編碼了關於圖像 $x$ 本身的先驗知識（例如，圖像應該是自然的、平滑的、稀疏的等）。在 Blind-PnP DM 中，這部分由預訓練的圖像擴散模型 $D_\alpha$ 隱式學習和表示。

    * $p(\theta)$ 或 $h(\theta) := -\log p(\theta)$：這是**測量算子參數先驗項 (Forward Model Parameters Prior Term)** 或參數先驗勢函數。它編碼了關於測量算子參數 $\theta$ 自身的先驗知識（例如，模糊核應該是平滑的、緊湊的等）。這部分由預訓練的參數擴散模型 $D_\beta$ 隱式學習和表示。

**公式 (8)：圖像採樣的似然步驟 ($z^{(k)}$)**

$z^{(k)} \sim \exp(-1/2 \ ||y-A(\theta^{(k)})z||^2 - 1/(2\rho_{x^k}) \ ||z-x^{(k)}||^2)$

* **意義**：這個公式描述了圖像採樣過程中的似然步驟，即如何從一個分佈中採樣輔助變量 $z$。這個分佈同時考慮了數據一致性與和當前圖像估計的耦合。它是將複雜的條件採樣分解為更易於處理的子問題的關鍵。

* **組成部分**：
    * $1/2 \ ||y-A(\theta^{(k)})z||^2$: 這是**數據保真項**。它確保採樣的 $z$ 在給定當前測量算子 $A(\theta^{(k)})$ 的情況下，與觀測數據 $y$ 保持一致。這項將 $z$ 拉向那些通過 $A(\theta^{(k)})$ 作用於 $z$ 後能產生 $y$ 的值。
    * $1/(2\rho_{x^k}) \ ||z-x^{(k)}||^2$: 這是**耦合項**。它將輔助變量 $z$ 與上一輪的圖像估計 $x^{(k)}$ 聯繫起來。控制 $\rho_{x^k}$ ＞ 0 控制這種耦合的強度。$\rho_{x^k}$ 越小，耦合越強，$z$ 就會被強制拉向 $x^{(k)}$。
    * **作用**：這個步驟對於測量模型引入圖像採樣過程至關重要。它有效地創建了一個圖像的「噪音版本」，這個版本既與觀測數據一致，又與之前的圖像估計相關聯。這個 $z^{(k)}$ 隨後作為輸入，供後續的先驗步驟（即圖像擴散模型）的使用。

**公式 (9)：參數採樣的似然步驟 ($v^{(k)}$)**

$v^{(k)} \sim \exp(-1/2 \ ||y-A(v)x^{(k+1)}||^2 - 1/(2\rho_{\theta^k}) \ ||v-\theta^{(k)}||^2)$

* **意義**：這個公式與公式 (8) 類似，但它描述的是測量算子參數採樣過程中的似然步驟，即如何從一個分佈中採樣輔助變量 $v$。這個分佈同樣考慮了數據一致性與和當前參數估計的耦合。

* **組成部分**：
    * $1/2 \ ||y-A(v)x^{(k+1)}||^2$: 這是**數據保真項**。它確保採樣的 $v$ 在給定當前圖像 $x^{(k+1)}$ 的情況下，與觀測數據 $y$ 保持一致。這項將 $v$ 拉向那些通過 $A(v)$ 作用於 $x^{(k+1)}$ 後能產生 $y$ 的值。
    * $1/(2\rho_{\theta^k}) \ ||v-\theta^{(k)}||^2$: 這是**耦合項**。它將輔助變量 $v$ 與上一輪的參數估計 $\theta^{(k)}$ 聯繫起來。控制 $\rho_{\theta^k}$ ＞ 0 控制這種耦合的強度。

    * **作用**：這個步驟對於測量模型參數採樣過程至關重要。它生成了一個參數的「噪音版本」，這個版本既與觀測數據一致，又與更新後的圖像估計相關聯。這個 $v^{(k)}$ 隨後作為輸入，供後續的先驗步驟（即參數擴散模型）使用。

總而言之，這些公式構成了 Blind-PnP DM 採樣策略的核心。公式 (5) 定義了最終的目標分佈，而公式 (8) 和 (9) 則代表了吉布斯採樣框架中的「似然」或「數據一致性」步驟，其中輔助變量 ($z$ 用於圖像，$v$ 用於參數) 被採樣以整合測量模型和先前的估計，為後續擴散模型（先驗）的應用做好準備。這些步驟共同確保了算法能夠在數據一致性與先驗合理性之間取得平衡，從而實現對圖像和測量算子參數的聯合估計。

## 五、數值驗證與實驗結果

為驗證 Blind-PnP DM 框架的有效性，研究人員在盲圖像去模糊問題上進行了全面的數值實驗。在盲圖像去模糊中，測量算子 $A(\theta)x$ 被建模為未知模糊核 $\theta$ 與未知圖像 $x$ 的卷積操作，即 $A(\theta)x = \theta \ast x$。

### 5.1 實驗設置

* **測試數據集**：實驗隨機選取了 100 張來自 FFHQ 數據集的真實圖像作為測試數據。
* **圖像擴散模型**：採用了從 **[[38] H. Chung, B. Sim, and J. C. Ye, “Come-closer-diffuse-faster:  Accelerating conditional diffusion models for inverse problems through  stochastic contraction,” in Proc. IEEE Conf. Comput. Vis. Pattern  Recognit., 2022.]** 獲取的預訓練圖像擴散模型。
* **模糊核擴散模型**：模糊核擴散模型則根據 **[[39] H. Chung, J. Kim, S. Kim, and J. C. Ye, “Parallel diffusion  models of operator and image for blind inverse problems,” in Proc. IEEE  Conf. Comput. Vis. Pattern Recognit., 2023.]** 的方法進行訓練。該模型在 10 萬個生成的 64x64 大小模糊核（包括高斯模糊核和運動模糊核）上訓練了 500 萬步，並使用了小型 U-Net 架構。測試用的高斯和運動模糊核也按照 **[[40] P. Dhariwal and A. Nichol, “Diffusion models beat gans on image synthesis,” Proc. Adv. Neural Inf. Process. Syst., 2021.]** 的方法生成。
* **超參數設定**：在實驗中，總迭代次數 $K$ 設定為 30。圖像的耦合強度時間表 $\rho_x^{(k)}$ 設定為 $\max(0.9^k * 0.3, 0.1)$，而測量算子參數的耦合強度時間表 $\rho_\theta^{(k)}$ 設定為 $\max(0.9^k * 0.1, 0.05)$。這些退火策略有助於算法的穩定收斂。

### 5.2 比較基準方法

Blind-PnP DM 的性能與多種現有基準方法進行了比較，包括：

* **Pan-DCP**：一種基於優化的方法，旨在聯合估計圖像和模糊核。
* **DeblurGANv2**：一種基於監督學習的方法，能夠通過直接重建圖像，但其主要限制在於缺乏估計模糊核的能力。DeblurGANv2 的結果是通過運行其公開代碼並使用預訓練權重獲得的。
* **BlindDDPS**：一種基於擴散模型的方法，在逆向擴散過程中能夠聯合生成圖像和模糊核。
* **GibbsDDRM**：另一種基於擴散模型的方法，同樣在逆向擴散過程中聯合生成圖像和模糊核。

### 5.3 結果分析

實驗結果通過定性視覺效果和定量指標兩方面進行了評估。

定性結果 (圖 1 和 圖 2)：
圖 1 展示了使用運動模糊核進行盲圖像去模糊的重建結果，而圖 2 則展示了使用高斯模糊核的結果。

- 兩幅圖都清晰地表明，Blind-PnPDM 能夠恢復人臉的精細細節，而其他非擴散模型方法（如 Pan-DCP 和 DeblurGANv2）則產生了更平滑的重建結果。
- 值得注意的是，Blind-PnPDM 的重建結果與真實圖像和模糊核的一致性更高。相比之下，其他基於擴散模型的方法（BlindDPS 和 GibbsDDRM）雖然也能產生清晰的圖像，但在細節和與真實情況的一致性方面則稍遜一籌。
- 圖中每個圖像頂部的方塊顯示了估計的模糊核，圖像左上角則標示了相應方法的 PSNR、SSIM 和 LPIPS 指標。

![Figure1.png](https://imgpoi.com/i/FV2C4V.png)

![Figure2.png](https://imgpoi.com/i/FV3ZFB.png)

**定量結果 (表 1)：** 表 1 提供了 Blind-PnPDM 與基準方法在盲圖像去模糊任務上的綜合定量評估，使用了失真度量（PSNR 和 SSIM）和感知度量（LPIPS）。PSNR 和 SSIM 值越高表示性能越好，而 LPIPS 值越低表示性能越好。

![Table1.png](https://imgpoi.com/i/FV3YGG.png)

- **校準列：** 指示該方法是否專門設計用於解決盲逆問題。Pan-DCP、BlindDPS 和 GibbsDDRM 屬於此類。雖然 Blind-PnPDM 處理盲逆問題，但在表格中未明確標記為「校準」方法，這可能與其採樣性質有關。
- **DM 列：** 指示該方法是否使用擴散模型作為先驗。BlindDPS、GibbsDDRM 和 Blind-PnPDM 均使用擴散模型。
- 性能表現：
  - 對於高斯模糊核，Blind-PnPDM 在 PSNR (27.13)、SSIM (0.802) 和 LPIPS (0.180) 所有指標上均取得了最佳性能。GibbsDDRM 則為第二佳表現。 
  - 對於運動模糊核，Blind-PnPDM 同樣在 PSNR (27.42)、SSIM (0.795) 和 LPIPS (0.176) 所有指標上表現最佳。GibbsDDRM 再次位居第二。

總體而言，數值驗證結果一致表明，Blind-PnPDM 在盲圖像去模糊任務中，無論是與非擴散模型方法還是其他擴散模型方法相比，都展現出卓越的性能，在定量指標和定性視覺質量上均表現出色 。這強烈支持了將盲逆問題視為一系列去噪子問題，並利用擴散模型強大先驗能力的有效性。

## 六、論文結論

此論文提出了 Blind-PnPDM，這是首個針對盲逆問題設計的即插即用（PnP）採樣方法 。該框架的核心思想是利用吉布斯採樣（Gibbs Sampling）的策略，交替地從圖像和未知測量算子參數各自的邊緣分佈中進行採樣 。每個邊緣分佈的採樣過程進一步分解為似然（Likelihood）和先驗（Prior）兩個步驟，其中先驗部分通過強大的擴散模型來建模。

通過在盲圖像去模糊問題上的數值驗證，Blind-PnPDM 展現了其卓越的有效性。實驗結果一致表明，與現有的基於擴散模型和非擴散模型的基準方法相比，Blind-PnPDM 在定量指標（如 PSNR、SSIM）和定性視覺質量（如 LPIPS）方面均取得了優異的性能 。這項工作不僅填補了即插即用文獻中處理盲逆問題的空白，更突顯了將盲逆問題視為一系列去噪子問題，並充分利用擴散模型強大表達能力作為先驗的巨大潛力。

## 七、想法

Blind-PnPDM 雖然在盲逆問題上取得了顯著進展，我可以理解他的本質就是使用兩個擴散模型進行交替影響，但仍有以下幾個潛在的改進方向：

1.  **提升計算效率：** Blind-PnPDM 採用交替式吉布斯採樣，並使用兩個擴散模型（一個用於圖像，一個用於測量算子參數），這在計算上可能非常密集且耗時，尤其是在處理高解析度圖像或需要大量迭代時。未來的改進方向可以探索更快的採樣策略，例如，研究如何減少擴散步驟數量（借鑒 DDIM 等加速採樣方法），或開發更高效的馬可夫鏈蒙地卡羅（MCMC）變體，以加速收斂並降低整體計算成本。

2.  **增強測量算子先驗模型的通用性：** Blind-PnPDM 依賴於針對特定測量算子類型（例如模糊核）預訓練的擴散模型 ($D_{\beta}$)。這意味著對於不同類型的盲逆問題（例如，未知的光學畸變或感測器缺陷），可能需要重新訓練一個新的 $D_{\beta}$，這會限制其在實際應用中的「即插即用」靈活性。未來的研究可以專注於開發更通用的測量算子擴散模型，使其能夠適應多種未知算子類型，而無需進行大量重新訓練，從而提高其泛化能力。

3.  **處理更複雜的盲逆問題：** 雖然 Blind-PnPDM 在盲圖像去模糊方面表現出色，但其在處理更廣泛、更複雜的盲逆問題（例如，具有非線性測量算子或非高斯噪聲的盲問題）方面的能力尚未充分探索（[如同DPS論文所做的工作](https://openreview.net/pdf/dd7f2e1f5581d91eb4c1ff34fec78b93d3dfa599.pdf)）。未來的改進可以擴展其框架，使其能夠穩健地處理這些更具挑戰性的場景，例如整合對多種噪聲模型（如泊松噪聲）或複雜非線性算子的先驗知識，以進一步拓寬其應用範圍。

